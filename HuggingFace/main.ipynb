{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = pipeline(\"text2text-generation\", model=\"facebook/blenderbot-400M-distill\")\n",
    "\n",
    "message = \"What is sport do you recommend in the winter?\"\n",
    "print(chatbot(message))\n",
    "\n",
    "\n",
    "del chatbot\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻译\n",
    "\n",
    "translation_bot = pipeline(task=\"translation\", model=\"facebook/nllb-200-distilled-600M\", torch_dtype=torch.float16)\n",
    "\n",
    "text = \"\"\"\n",
    "Her panda is fridenly.\n",
    "\"\"\"\n",
    "\n",
    "print(translation_bot(text, src_lang=\"eng_Latn\", tgt_lang=\"fra_Latn\"))\n",
    "\n",
    "del translation_bot\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成摘要\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\", torch_dtype=torch.float16)\n",
    "\n",
    "text = \"\"\"\n",
    "The Hugging Face Hub is a platform with over 900k models, 200k datasets, and 300k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. The Hub works as a central place where anyone can explore, experiment, collaborate, and build technology with Machine Learning. Are you ready to join the path towards open source Machine Learning?\n",
    "\"\"\"\n",
    "\n",
    "print(summarizer(text, min_length=5, max_length=20))\n",
    "\n",
    "del summarizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences1 = ['The cat sits outside', 'A man is playing guitar', 'The movies are awesome']\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "print(embeddings1)\n",
    "\n",
    "sentences2 = ['The dog plays in the garden', 'A woman watches TV', 'The new movie is so great']\n",
    "embeddings2 = model.encode(sentences1, convert_to_tensor=True)\n",
    "print(embeddings2)\n",
    "\n",
    "cosine_score = util.cos_sim(embeddings1, embeddings2)  # 余弦距离\n",
    "print(cosine_score)\n",
    "\n",
    "for i in range(len(cosine_score)):\n",
    "    print(f'{sentences1[i]}\\t\\t{sentences2[i]}\\t\\tScore: {cosine_score[i][i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
